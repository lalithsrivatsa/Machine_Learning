{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIwFwgiMY7Ff7P8TTBpv3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalithsrivatsa/Machine_Learning/blob/master/ML101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install catboost"
      ],
      "metadata": {
        "id": "rvBCgoN6NwrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46bdc27-4eb9-4ce8-a9b4-5f36d3bd9a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbp5KQ7yMhxI"
      },
      "outputs": [],
      "source": [
        "# Multi-model REGRESSION: Linear/Lasso/Ridge/DecisionTree/Bagging/RF/AdaBoost/CatBoost\n",
        "\n",
        "# - CV hyperparameter tuning for each model\n",
        "\n",
        "# - Single holdout evaluation\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.base import clone\n",
        "\n",
        "# Optional: CatBoost (install via pip)\n",
        "\n",
        "from catboost import CatBoostRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(42)\n",
        "# 1) Create synthetic data ----------------------------------------------------\n",
        "n = 3000\n",
        "age = rng.normal(40, 12, n).clip(18, 80)\n",
        "income = rng.lognormal(mean=10, sigma=0.5, size=n)\n",
        "tenure = rng.exponential(scale=5, size=n)\n",
        "score1 = rng.normal(0, 1, n)\n",
        "score2 = rng.normal(5, 2, n)\n",
        "city = rng.choice([\"NY\", \"SF\", \"CHI\", \"DAL\"], size=n, p=[0.35, 0.25, 0.25, 0.15])\n",
        "segment = rng.choice([\"A\", \"B\", \"C\"], size=n, p=[0.5, 0.3, 0.2])\n",
        "\n",
        "y = (\n",
        "    0.05 * age\n",
        "    + 0.00003 * income\n",
        "    + 0.2 * np.log1p(tenure)\n",
        "    + 0.8 * score1\n",
        "    - 0.4 * score2\n",
        "    + (city == \"SF\") * 1.5\n",
        "    + (segment == \"A\") * 0.8\n",
        "    + rng.normal(0, 1.2, n)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"age\": age, \"income\": income, \"tenure\": tenure,\n",
        "    \"score1\": score1, \"score2\": score2,\n",
        "    \"city\": city, \"segment\": segment, \"target\": y\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "# Inject some missingness\n",
        "for col in [\"age\",\"income\",\"tenure\"]:\n",
        "    idx = rng.choice(n, size=int(0.05*n), replace=False)\n",
        "    df.loc[idx, col] = np.nan\n",
        "idx = rng.choice(n, size=int(0.02*n), replace=False)\n",
        "df.loc[idx, \"segment\"] = np.nan\n",
        "\n",
        "\n",
        "target = \"target\"\n",
        "num_cols = [\"age\",\"income\",\"tenure\",\"score1\",\"score2\"]\n",
        "cat_cols = [\"city\",\"segment\"]\n",
        "\n",
        "X = df[num_cols + cat_cols].copy()\n",
        "y = df[target].copy()"
      ],
      "metadata": {
        "id": "4-uaHHpFM4o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.head())\n",
        "print(X.describe())\n",
        "print(X.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmg5kvWpPCXB",
        "outputId": "fd76bed2-202d-42db-e004-dc7a483e56ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         age        income     tenure    score1    score2 city segment\n",
            "0  45.960570   8485.348260   2.050758  0.568645  4.093481  DAL       A\n",
            "1  38.340828  14325.658292   1.186265  0.382922  8.436879   NY       C\n",
            "2  47.772262  17911.481903   1.878430  1.626431  2.420648   NY       A\n",
            "3  58.276358  56604.503529   0.985193  0.236043  7.507470   NY       A\n",
            "4  37.190160  29093.689159  11.609661 -0.386023  3.470302   NY       A\n",
            "               age         income       tenure       score1       score2\n",
            "count  2850.000000    2850.000000  2850.000000  3000.000000  3000.000000\n",
            "mean     40.470615   24531.223885     4.842064    -0.008811     5.040783\n",
            "std      11.513878   13120.434262     4.721768     0.967599     2.021178\n",
            "min      18.000000    4499.169456     0.001205    -3.922400    -1.642229\n",
            "25%      32.357557   15430.128475     1.460349    -0.660915     3.694789\n",
            "50%      40.223701   21743.307498     3.410642    -0.005663     5.037790\n",
            "75%      48.064605   30308.949649     6.663398     0.639934     6.390844\n",
            "max      80.000000  111473.980599    38.056681     3.377768    11.857821\n",
            "age        150\n",
            "income     150\n",
            "tenure     150\n",
            "score1       0\n",
            "score2       0\n",
            "city         0\n",
            "segment     60\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Preprocessors ------------------------------------------------------------\n",
        "\n",
        "# Scaled preprocessor (for linear models)\n",
        "\n",
        "num_scaled = Pipeline([\n",
        "\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "\n",
        "    (\"scale\", StandardScaler()),\n",
        "\n",
        "])\n",
        "\n",
        "cat_ohe = Pipeline([\n",
        "\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "pre_scaled = ColumnTransformer([\n",
        "\n",
        "    (\"num\", num_scaled, num_cols),\n",
        "\n",
        "    (\"cat\", cat_ohe,   cat_cols),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Unscaled preprocessor (trees/boosting don’t need scaling)\n",
        "\n",
        "num_unscaled = Pipeline([\n",
        "\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "\n",
        "])\n",
        "\n",
        "pre_unscaled = ColumnTransformer([\n",
        "\n",
        "    (\"num\", num_unscaled, num_cols),\n",
        "\n",
        "    (\"cat\", cat_ohe,      cat_cols),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "t0ChLrn6NHrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3) Holdout split ------------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "\n",
        "    X, y, test_size=0.2, random_state=42\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "peVw_-cFNLU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Define models + param grids ---------------------------------------------\n",
        "models = {\n",
        "    # Linear family (use scaled preprocessor)\n",
        "    \"LinearRegression\": {\n",
        "        \"pre\": pre_scaled,\n",
        "        \"est\": LinearRegression(),\n",
        "        \"grid\": {\n",
        "            # LinearRegression has no classic hyperparams; keep empty or add fit_intercept toggle\n",
        "            \"model__fit_intercept\": [True, False],\n",
        "            # \"model__positive\": [True, False],  # available in recent versions\n",
        "        }\n",
        "    },\n",
        "    \"Lasso\": {\n",
        "        \"pre\": pre_scaled,\n",
        "        \"est\": Lasso(max_iter=10000, random_state=42),\n",
        "        \"grid\": {\n",
        "            \"model__alpha\": [0.001, 0.01, 0.1, 1.0]\n",
        "        }\n",
        "    },\n",
        "    \"Ridge\": {\n",
        "        \"pre\": pre_scaled,\n",
        "        \"est\": Ridge(random_state=42),\n",
        "        \"grid\": {\n",
        "            \"model__alpha\": [0.1, 1.0, 10.0, 100.0]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Tree/ensemble family (use unscaled preprocessor)\n",
        "    \"DecisionTree\": {\n",
        "        \"pre\": pre_unscaled,\n",
        "        \"est\": DecisionTreeRegressor(random_state=42),\n",
        "        \"grid\": {\n",
        "            \"model__max_depth\": [None, 6, 10, 16],\n",
        "            \"model__min_samples_split\": [2, 5, 10],\n",
        "            \"model__min_samples_leaf\": [1, 2, 5]\n",
        "        }\n",
        "    },\n",
        "    \"Bagging\": {\n",
        "        \"pre\": pre_unscaled,\n",
        "        \"est\": BaggingRegressor(\n",
        "            estimator=DecisionTreeRegressor(random_state=42),\n",
        "            random_state=42, n_jobs=-1\n",
        "        ),\n",
        "        \"grid\": {\n",
        "            \"model__n_estimators\": [100, 300],\n",
        "            \"model__max_samples\": [0.6, 0.8, 1.0],\n",
        "            \"model__max_features\": [0.6, 0.8, 1.0]\n",
        "        }\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"pre\": pre_unscaled,\n",
        "        \"est\": RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "        \"grid\": {\n",
        "            \"model__n_estimators\": [300, 600],\n",
        "            \"model__max_depth\": [None, 10, 16],\n",
        "            \"model__min_samples_split\": [2, 5],\n",
        "            \"model__min_samples_leaf\": [1, 2]\n",
        "        }\n",
        "    },\n",
        "    \"AdaBoost\": {\n",
        "        \"pre\": pre_unscaled,\n",
        "        \"est\": AdaBoostRegressor(\n",
        "            estimator=DecisionTreeRegressor(random_state=42),\n",
        "            random_state=42\n",
        "        ),\n",
        "        \"grid\": {\n",
        "            \"model__n_estimators\": [200, 400],\n",
        "            \"model__learning_rate\": [0.05, 0.1, 0.2],\n",
        "            \"model__estimator__max_depth\": [2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    \"CatBoost\": {\n",
        "        \"pre\": pre_unscaled,\n",
        "        \"est\": CatBoostRegressor(\n",
        "            loss_function=\"RMSE\",\n",
        "            random_seed=42,\n",
        "            verbose=False,  # silence training logs\n",
        "        ),\n",
        "        \"grid\": {\n",
        "            \"model__depth\": [4, 6, 8],\n",
        "            \"model__learning_rate\": [0.03, 0.06, 0.1],\n",
        "            \"model__l2_leaf_reg\": [1, 3, 5],\n",
        "            \"model__iterations\": [500, 800]\n",
        "        }\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "4lfSAIwONPGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5) CV + GridSearch for each model ------------------------------------------\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = []\n",
        "\n",
        "for name, cfg in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    pipe = Pipeline([\n",
        "        (\"prep\", cfg[\"pre\"]),\n",
        "        (\"model\", clone(cfg[\"est\"]))\n",
        "    ])\n",
        "\n",
        "    gs = GridSearchCV(\n",
        "        estimator=pipe,\n",
        "        param_grid=cfg[\"grid\"],\n",
        "        scoring=\"neg_root_mean_squared_error\",\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        refit=True,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    gs.fit(X_train, y_train)\n",
        "    best_rmse_cv = -gs.best_score_\n",
        "    print(\"Best CV RMSE:\", round(best_rmse_cv, 4))\n",
        "    print(\"Best params:\", gs.best_params_)\n",
        "\n",
        "    # Holdout evaluation\n",
        "    best_model = gs.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    rmse = root_mean_squared_error(y_test, y_pred)\n",
        "    mae  = mean_absolute_error(y_test, y_pred)\n",
        "    r2   = r2_score(y_test, y_pred)\n",
        "    print(f\"Holdout -> RMSE: {rmse:.4f} | MAE: {mae:.4f} | R2: {r2:.4f}\")\n",
        "\n",
        "    if hasattr(best_model.named_steps[\"model\"], \"coef_\"):\n",
        "      # Get the coefficients from the model step in the pipeline\n",
        "      coefficients = best_model.named_steps[\"model\"].coef_\n",
        "\n",
        "      # Get the feature names from the preprocessing step in the pipeline\n",
        "      feature_names = best_model.named_steps[\"prep\"].get_feature_names_out()\n",
        "\n",
        "      # Create a pandas Series for easy viewing\n",
        "      importances = pd.Series(coefficients, index=feature_names)\n",
        "\n",
        "      print(\"\\n--- Top 10 Feature Importances ---\")\n",
        "      # Sort by the absolute value to see the most impactful features\n",
        "      print(importances.abs().sort_values(ascending=False).head(10))\n",
        "      # --------------------------------------------------\n",
        "\n",
        "\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"cv_rmse\": best_rmse_cv,\n",
        "        \"holdout_rmse\": rmse,\n",
        "        \"holdout_mae\": mae,\n",
        "        \"holdout_r2\": r2,\n",
        "        \"best_params\": gs.best_params_\n",
        "    })\n"
      ],
      "metadata": {
        "id": "abDNlusDNbhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5397fe8-49fc-45b5-fb51-84e4bdce16c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LinearRegression ===\n",
            "Best CV RMSE: 1.2183\n",
            "Best params: {'model__fit_intercept': True}\n",
            "Holdout -> RMSE: 1.2143 | MAE: 0.9794 | R2: 0.6182\n",
            "\n",
            "--- Top 10 Feature Importances ---\n",
            "cat__city_SF      1.086871\n",
            "num__score2       0.849713\n",
            "num__score1       0.821383\n",
            "num__age          0.557701\n",
            "cat__segment_A    0.490010\n",
            "cat__city_DAL     0.375353\n",
            "cat__city_CHI     0.374654\n",
            "num__income       0.351114\n",
            "cat__city_NY      0.336864\n",
            "cat__segment_C    0.276981\n",
            "dtype: float64\n",
            "\n",
            "=== Lasso ===\n",
            "Best CV RMSE: 1.2182\n",
            "Best params: {'model__alpha': 0.001}\n",
            "Holdout -> RMSE: 1.2146 | MAE: 0.9796 | R2: 0.6181\n",
            "\n",
            "--- Top 10 Feature Importances ---\n",
            "cat__city_SF      1.422554\n",
            "num__score2       0.848706\n",
            "num__score1       0.820325\n",
            "cat__segment_A    0.701170\n",
            "num__age          0.556819\n",
            "num__income       0.350333\n",
            "num__tenure       0.118395\n",
            "cat__segment_C    0.058741\n",
            "cat__city_CHI     0.030735\n",
            "cat__city_DAL     0.029423\n",
            "dtype: float64\n",
            "\n",
            "=== Ridge ===\n",
            "Best CV RMSE: 1.2183\n",
            "Best params: {'model__alpha': 1.0}\n",
            "Holdout -> RMSE: 1.2143 | MAE: 0.9794 | R2: 0.6182\n",
            "\n",
            "--- Top 10 Feature Importances ---\n",
            "cat__city_SF      1.084959\n",
            "num__score2       0.849374\n",
            "num__score1       0.821029\n",
            "num__age          0.557494\n",
            "cat__segment_A    0.489468\n",
            "cat__city_DAL     0.374427\n",
            "cat__city_CHI     0.374026\n",
            "num__income       0.350998\n",
            "cat__city_NY      0.336505\n",
            "cat__segment_C    0.276551\n",
            "dtype: float64\n",
            "\n",
            "=== DecisionTree ===\n",
            "Best CV RMSE: 1.5104\n",
            "Best params: {'model__max_depth': 6, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5}\n",
            "Holdout -> RMSE: 1.5266 | MAE: 1.2093 | R2: 0.3966\n",
            "\n",
            "=== Bagging ===\n",
            "Best CV RMSE: 1.3085\n",
            "Best params: {'model__max_features': 1.0, 'model__max_samples': 0.6, 'model__n_estimators': 300}\n",
            "Holdout -> RMSE: 1.3103 | MAE: 1.0492 | R2: 0.5555\n",
            "\n",
            "=== RandomForest ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CV RMSE: 1.3088\n",
            "Best params: {'model__max_depth': 10, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}\n",
            "Holdout -> RMSE: 1.3102 | MAE: 1.0493 | R2: 0.5556\n",
            "\n",
            "=== AdaBoost ===\n",
            "Best CV RMSE: 1.3268\n",
            "Best params: {'model__estimator__max_depth': 4, 'model__learning_rate': 0.2, 'model__n_estimators': 400}\n",
            "Holdout -> RMSE: 1.3263 | MAE: 1.0580 | R2: 0.5446\n",
            "\n",
            "=== CatBoost ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CV RMSE: 1.2418\n",
            "Best params: {'model__depth': 4, 'model__iterations': 500, 'model__l2_leaf_reg': 3, 'model__learning_rate': 0.03}\n",
            "Holdout -> RMSE: 1.2333 | MAE: 0.9884 | R2: 0.6062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Compare models -----------------------------------------------------------\n",
        "res_df = pd.DataFrame(results).sort_values(\"holdout_rmse\")\n",
        "print(\"\\n=== Model Comparison (sorted by holdout RMSE) ===\")\n",
        "print(res_df[[\"model\",\"cv_rmse\",\"holdout_rmse\",\"holdout_mae\",\"holdout_r2\"]])\n",
        "print(\"\\nBest params per model (peek):\")\n",
        "for row in results:\n",
        "    print(row[\"model\"], \"->\", row[\"best_params\"])"
      ],
      "metadata": {
        "id": "2G2ruvHhMsYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893edd63-0451-45a9-bd88-f4993d8bc024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Comparison (sorted by holdout RMSE) ===\n",
            "              model   cv_rmse  holdout_rmse  holdout_mae  holdout_r2\n",
            "0  LinearRegression  1.218256      1.214317     0.979415    0.618232\n",
            "2             Ridge  1.218250      1.214325     0.979442    0.618227\n",
            "1             Lasso  1.218179      1.214552     0.979571    0.618084\n",
            "7          CatBoost  1.241800      1.233347     0.988358    0.606173\n",
            "5      RandomForest  1.308784      1.310164     1.049334    0.555587\n",
            "4           Bagging  1.308481      1.310270     1.049200    0.555515\n",
            "6          AdaBoost  1.326802      1.326264     1.058007    0.544598\n",
            "3      DecisionTree  1.510409      1.526592     1.209347    0.396633\n",
            "\n",
            "Best params per model (peek):\n",
            "LinearRegression -> {'model__fit_intercept': True}\n",
            "Lasso -> {'model__alpha': 0.001}\n",
            "Ridge -> {'model__alpha': 1.0}\n",
            "DecisionTree -> {'model__max_depth': 6, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5}\n",
            "Bagging -> {'model__max_features': 1.0, 'model__max_samples': 0.6, 'model__n_estimators': 300}\n",
            "RandomForest -> {'model__max_depth': 10, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}\n",
            "AdaBoost -> {'model__estimator__max_depth': 4, 'model__learning_rate': 0.2, 'model__n_estimators': 400}\n",
            "CatBoost -> {'model__depth': 4, 'model__iterations': 500, 'model__l2_leaf_reg': 3, 'model__learning_rate': 0.03}\n"
          ]
        }
      ]
    }
  ]
}